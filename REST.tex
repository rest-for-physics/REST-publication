%%%%%% REST DATA GENERATION PROCESSING CHAPTER %%%%%%%
\section{REST as a data analysis framework.}\label{sc:REST}

%% Paragraph introducing REST as a software development
RESTSoft (Rare Event Searches with TPCs Software) is a collaborative software effort providing a common framework for acquisition, simulation, and data analysis for gaseous Time Projection Chambers (TPCs)\,\cite{tomas2013development}. REST is composed of a set of libraries written in C++ and is fully integrated in ROOT~\cite{ROOT}, i.e. all REST classes inherit from TObject and can be read/accessed/written using the ROOT I/O interface. The only structural dependence is related to ROOT libraries, while other packages, as \emph{Geant4}~\cite{Agostinelli:2002hh} or \emph{Garfield++}~\cite{Garfield}, can be optionally integrated and used within the REST framework when generating or processing Monte Carlo data.

%% Paragraph dedicated to REST progress and philosophy % Description of metadata+data concept
During the last years, major upgrades took place on the REST core libraries\,\cite{Galan_8thTPC}. An important feature introduced in REST is that \emph{metadata} and \emph{event data} are stored together in a unique file. We understand by \emph{metadata} any information required to give meaning to the data registered in the \emph{event data}, as it can be the initial run data taking conditions, the geometry of the detector, the gas properties, or the detector readout topology. Additionally, any input or output parameters, required during the processing or transformation of \emph{event data}, using \emph{event processes}, will be stored as \emph{metadata}. Any previous existing \emph{metadata} structures inside the REST input file will be transferred to any future output, assuring full traceability, as well as reproducibility of results obtained with a particular dataset.

%% Monte Carlo and experimental common processing discussion
An ambitious feature of REST is its capability to analyze Monte Carlo and experimental data using common \emph{event processes}. This is possible by using existing REST \emph{event processes} to condition the input data generated, for example, by a \emph{Geant4} Monte Carlo simulation. After an appropriate \emph{event data} conditioning, our Monte Carlo generated event will reproduce the \emph{rawdata} of the detector (as it is shown in~\ref{sc:RawProcessing}). Once we are at that stage, we can benefit from using the same \emph{event processes} to analyze Monte Carlo and real experimental data. A realistic Monte Carlo \emph{rawdata} reconstruction will allow us to assess, validate and optimize the processes that will be involved in the real event reconstruction and analysis even before the start of the physics run of the experiment.
%%  An \emph{event process} allows to transform of extract information from a given \emph{event type}.

In the following subsections, we recall the definitions of the different components of REST, \emph{viz.} \emph{event types}, \emph{event processes}, and \emph{analysis tree}. These definitions will serve as a reference for the article. Note that we do this having in mind the case where the physics variables of interest are local energy deposits, called hits, and the signal is digitized by a sampling ADC. The REST software is versatile enough, though, to handle many other cases. We include here only those components of REST that are relevant to our study.

\subsection{Event types}

%% Basic introduction of data types and processes
REST defines basic \emph{event types}, or data structures, commonly used to store \emph{event data} generated during the data acquisition, production and/or \emph{event data} processing. The definition of a reduced set of basic \emph{event types} allows for better inter-process connectivity. The following data structures defined in REST are used in our study.

\begin{itemize}
\item \emph{TRestHitsEvent:} This structure contains an arbitrary number of elements or hits used to store a physical variable, $\phi_i$, defined in a 3-dimensional coordinate system $(x_i, y_i, z_i)$. In our study, we use this \emph{event type} to describe the energy depositions on the volume of the detector.
\item \emph{TRestG4Event:} It is a natural extension of \emph{TRestHitsEvent} containing additional information gathered during the \emph{Geant4} simulation, such as the physical interaction associated to the hit, and the volume of the simulation geometry where the interaction took place.
\item \emph{TRestTrackEvent:} A more sophisticated structure where hits are grouped into tracks, following e.g., a proximity criterion. Tracks can, in turn, be grouped into higher level structures. An \emph{identification number} and a \emph{parent number} are assigned to each object and allow to keep the record of its genealogy. A track that is not associated to a parent track will be denominated as an \emph{origin track}, while a track with no daughter tracks will be denominated as a \emph{top-level track}. Therefore, in this scheme we may distinguish different track levels related to the number of track generations.

\item \emph{TRestRawSignalEvent:} Stores the digitized signal samples, in the shape of fixed size arrays. Each array corresponds to one front-end electronics channel, and is assigned a logical \emph{signalId}. The set of \emph{signalId}'s is mapped to the geometry of the detection with help of a \emph{readout metadata} table, typically known as \emph{decoding}. The arrays generally describe the time evolution of the signal.
\item \emph{TRestTimeSignalEvent:} It contains an arbitrary number of non-fixed size arrays that define a physical quantity, $\phi_i$, at arbitrary times, $t_i$, expressed in physical time units. Each array dataset may contain a different number of data points. This kind of \emph{event type} can be exploited, e.g. for experimental data reduction or storage of timed signals produced in Monte Carlo generated data. As in the case of a \emph{TRestRawSignalEvent}, each array is also identified using a \emph{signalId} associated to the electronic channels described inside the \emph{readout metadata} description.

\end{itemize}

We stress again that the \emph{event types} defined in REST aspire to be as generic and abstract as possible. It is the role of \emph{processes}, and other \emph{metadata} information used during the data processing, to provide a physical meaning, or final interpretation, to the information that is contained in our \emph{event type}. In the scenario where certain specialization is required, as it is the case of a \emph{TRestG4Event}, an existing REST \emph{event process} will be capable to transform this specialized, or dedicated, \emph{event type} into an existing and more basic one, as it is a \emph{TRestHitsEvent}.

%% Data chain introduction
The \emph{event types} described are not only containers to store \emph{event data} in REST, but they implement methods associated to the nature of each data structure, as e.g. spatial rotation or translation of coordinates in a \emph{TRestHitsEvent} or time signal processing methods in a \emph{TRestRawSignalEvent}, as e.g. differentiation, smoothing or Fast Fourier Transform (FFT) methods, together with prototyped methods, i.e. common to all the \emph{event types}, for visualizing and printing the contents of a particular stored event.

\subsection{Event processes}\label{sc:evProcesses}

%% Introduction of REST process interconnectivity and modularity
REST offers a large variety of \emph{event processes} operating on the basic \emph{event types} in order to manipulate the \emph{event data}, transform it and extract relevant information in the intermediate steps taking place during a particular \emph{event data} processing chain. An \emph{event process} in REST is modular, and it can be integrated in REST by fixing only its input and output \emph{event types}. In other words, any \emph{event process} that participates in a data processing chain must satisfy that its input \emph{event type} corresponds with the output \emph{event type} of the previous \emph{event process}, although there are exceptions as will be described in~\ref{sc:anTree}.

Therefore, \emph{event processes} can be classified as processes that transform an \emph{event type} into another, i.e. \emph{conversion processes}, and those which operate in a particular \emph{event type}, i.e. \emph{hit}, \emph{raw signal} or \emph{track processes}, in which the output \emph{event type} remains unchanged (although its content - the \emph{event data} - will usually be transformed). In the following sub-sections we provide a description of the different processes involved in our data processing. A full, detailed and up-to-date list of documented processes will be available at~\cite{RESTsultan} for further reference.

\subsubsection{ Conversion processes }\label{sc:convPcs}

%REST modularity and processes connectivity is assured by offering forward and backward \emph{event processes} that can transform an existing \emph{event type} into another.
\begin{itemize}
	\item \emph{TRestG4ToHitsProcess:} A simple process to transform a \emph{TRestG4Event} into a \emph{TRestHitsEvent}, visualized in Figure~\ref{fig:EvReconstruction}(a). Any specific hits information related to \emph{Geant4} will be lost after this step. Then, the only way in REST to have this information available at the end of the data processing chain will be through the \emph{analysis tree}, described in~\ref{sc:anTree}.

\item \emph{TRestHitsToSignalProcess:} This process produces a time projection of the primary electron positions in the TPC volume into the readout plane of the detector, producing the result shown in Figure~\ref{fig:EvReconstruction}(c). The coordinates of hits $(x_i, y_i, z_i)$ stored in a \emph{TRestHitsEvent} are transformed into a \emph{TRestTimeSignalEvent}. This process uses the REST \emph{readout metadata} structure (described in detail on~\ref{sc:readout}) to associate each hit coordinates $(x_i, y_i)$ with a detector \emph{readout channel}\footnote{As an argument to support this description we assume here that the field drifting the electrons is defined along the $z$-axis, although the readout plane can be placed in any arbitrary orientation.}, and perform a spatial to time conversion of the $z_i$ coordinate using the readout plane position and the drift velocity of electrons in the gas. The gas properties can be introduced directly as an input metadata parameter, or extracted from a specific metadata class, named \emph{TRestGas}, that interfaces with \emph{Garfield++} to obtain the properties of any gas mixture as calculated by \emph{Magboltz}. A sampling time, $\delta t$, can be provided optionally to discretize the resulting time values at the output \emph{TRestTimeSignalEvent}.

\item \emph{TRestSignalToHitsProcess:} The inverse process of a \emph{TRestHitsToSignalProcess}, producing the result shown in Figure~\ref{fig:EvReconstruction}(d). We recover, or reconstruct, the hit coordinates using the time information inside a \emph{TRestTimeSignalEvent} and the gas properties. The reconstructed coordinates are obtained using the \emph{readout metadata} description and the corresponding \emph{readout channel} number, associated to each \emph{signalId}.
% Say something more about 2d/3d here?

\begin{figure}[h]
\centering
\begin{tabular}{cc}
    \includegraphics[totalheight=6.5cm]{figureA1a.eps} &
    \includegraphics[totalheight=6.5cm]{figureA1b.eps} \\
	(a) & (b) \\
	& \\
    \includegraphics[totalheight=6.5cm]{figureA1c.eps} &
    \includegraphics[totalheight=6.5cm]{figureA1d.eps} \\
	(c) & (d) \\
	& \\
\end{tabular}
\caption{Representation of different event type outputs after different \emph{event processes} on the simulation of \XeNLDBDEvt. (a) Top-left panel visualizes a \emph{TRestG4Event} type, and represents the XZ-plane projection of the charge density of the 3-dimensional event. (b) Top-right panel shows a \emph{TRestHitsEvent} event type after applying the \emph{TRestElectronDiffusionProcess} where we can appreciate the effect of electron diffusion in a xenon + 1\%TMA gas mixture at 10\,bar, the readout plane is placed at $z=990$\,mm. (c) Bottom-left panel shows a \emph{TRestTimeSignalEvent} type after the conversion by a \emph{TRestHitsToSignalProcess}. (d) Bottom-right panel shows a \emph{TRestHitsEvent} type after the reconstruction using \emph{TRestSignalToHitsProcess}. A scatter plot is used in this case to emphasize the effect introduced by the 3mm-pitch detector readout that can be observed along the x-axis, and the 200\,ns sampling rate of the electronics on the z-axis. At this stage the \emph{TRestHitsEvent} is not anymore a 3-dimensional event, since we used here the PandaX-III stripped readout described on~\ref{sc:readout}.}
    \label{fig:EvReconstruction}
\end{figure}

\item \emph{TRestSignalToRawSignalProcess:} This process takes as input a \emph{TRestTimeSignalEvent} type and samples its contents into a fixed data array compatible with the \emph{TRestRawSignalEvent} output type, i.e. fixing the number of data points and sampling time, $\delta t$, which are provided as an input parameter to this process. A reference time, or \emph{trigger definition}, is used to define the physical time corresponding to the first sample of the resulting data array. Figure~\ref{fig:triggerDefinition} describes one of the trigger methods available on this process which we use later in this study.

\begin{figure}[]
\centering
\includegraphics[totalheight=6.5cm]{figureA2.eps}
\caption{A figure illustrating the trigger definition using the threshold method implemented in \emph{TRestSignalToRawSignalProcess} for \XeNLDBDEvt. The filled curve, in red, represents the charge distribution (in arbitrary units not represented on this plot) as a function of the electron drift time. The blue curve is constructed with the integral of the charges (with magnitude represented on the y-axis of this plot) in a fixed time width, here of about $\sim$50\,$\mu$s, and corresponding to the half size of the acquisition window of the electronics, of about $\sim$100\,$\mu$s. When the integration exceeds a certain threshold $E_{th}$, in this case equal to $Q_{\beta\beta}/2$ of $^{136}$Xe, the center of the acquisition window is fixed. The resulting acquisition window is represented by $t_{Start}$ and $t_{End}$. An additional offset is introduced on the definition of $t_{Start}$ to assure few time bins will be available for \emph{baseline} definition during the \emph{raw signal} event processing. } 
\label{fig:triggerDefinition}
\end{figure}

%\item \emph{ TRestSignalZeroSuppresionProcess: } We are not using this process in this work.

\item \emph{TRestHitsToTrackProcess:} This process takes as input a \emph{TRestHitsEvent} type and transforms it into a \emph{TRestTrackEvent}. The hit inter-distances inside the input event are evaluated, and those which fall within a certain distance will be assigned to the same identifiable \emph{track}. This distance is introduced as a metadata input parameter to the process, named \emph{cluster distance}. The algorithm starts creating a first track by adding an arbitrary and unassociated hit\footnote{A hit that does not belong yet to any \emph{track}}. The \emph{track} definition will only end when no more unassociated hits are found to satisfy the inter-distance relation with - and this is important - \emph{any} of the hits already added to the \emph{track}, i.e. the inter-distances are evaluated recursively. If after ending the definition of the first track there are still unassociated hits, the process continues to define a second track, and successively. The process ends when no more unassociated hits are found inside the \emph{TRestHitsEvent}.

\end{itemize}

\subsubsection{ Hit processes } 
\begin{itemize}

	\item \emph{TRestElectronDiffusionProcess:} This process uses the longitudinal and transverse coefficients of a particular gas mixture to emulate the relative deviation of electrons from their original positions in \emph{TRestHitsEvent}, presumably produced by primary ionization. The energy of each hit found inside the input \emph{TRestHitsEvent} is converted to the corresponding number of primary electrons that would be produced in the ionization process. Each electron will be a new hit in the output \emph{TRestHitsEvent} structure, and their coordinates will be randomly deviated following a Gaussian distribution related to the gas parameters, longitudinal and transverse diffusion coefficients, and the distance to the readout plane, which is given as metadata input. The result of applying this process is shown in Figure~\ref{fig:EvReconstruction}(b). This process may optionally add the possibility to include the effect of electron attachment.

\item \emph{TRestHitsSmearingProcess:} This process smears the energy of the input \emph{TRestHitsEvent} according to a Gaussian distribution described by parameters given as metadata input.% This process is used to introduce an artificial energy resolution.
\end{itemize}

\subsubsection{ Track processes for $0\nu\beta\beta$ topology }\label{sc:trackProcesses}

\begin{itemize}

	\item \emph{TRestTrackReductionProcess:} This process reduces the number of hits in each of the tracks stored in a \emph{TRestTrackEvent}, as seen in Figure~\ref{fig:TopologyProcess}(a). An input metadata parameter, $N_{max}$, specifies the maximum number of hits on each of the reduced tracks at the output \emph{TRestTrackEvent}. The closest hits are merged iteratively till the $N_{max}$ condition is satisfied. When \emph{two} hits are merged, the resulting hit position is calculated weighting the energy of each merged hit. The input \emph{parent tracks} are also stored in the output \emph{TRestTrackEvent}, together with the reduced tracks which acquire a relation of inheritance.

	\item \emph{TRestTrackPathMinimizationProcess:} This process operates only on each of the \emph{top-level tracks} found in \emph{TRestTrackEvent} and - using graph theory - finds the shortest path that connects all the hits within each track, as seen in Figure~\ref{fig:TopologyProcess}(b). We have integrated in this process a \emph{Held-Karp} algorithm~\cite{held1962dynamic} optimized for problems that contain between 25 and 35 nodes. This algorithm was extracted from the \emph{Concorde} Travel Sales Problem (TSP) libraries~\cite{Applegate:2007:TSP:1374811,concorde}. It is important to notice that the minimization is performed in a closed loop, i.e. the extremes of the physical track are not properly identified at the end of this process. From now on, we will denominate two consecutive hits as \emph{connected hits}.

	\item \emph{TRestTrackReconnectionProcess:} This process will be commonly used in combination with \emph{TRestTrackPathMinimizationProcess}. This process will detect unphysical path connections between the hits, or nodes. We understand by unphysical connection a distance between nodes that is larger than the average by a certain number of sigmas, or where no hits from the \emph{origin track} are found in between, as seen in Figure~\ref{fig:TopologyProcess}(c). The track is split at those unphysical connections and reconnected with the closest hit. Using this technique, the extremes of the physical track are found naturally. Although it was not used in our analysis, this process allows to identify secondary track branches of complex event tracks when reconnection is not possible.

\end{itemize}

\begin{figure}
\centering
\begin{tabular}{ccc}
    \includegraphics[totalheight=4.9cm]{figureA3a.eps} &
    \includegraphics[totalheight=4.9cm]{figureA3b.eps} &
    \includegraphics[totalheight=4.9cm]{figureA3c.eps} \\
	(a) & (b) & (c) \\
\end{tabular}
\caption{A \emph{TRestTrackEvent} representation of \XeNLDBDEvt~after the different track processes used for physical track identification. This event corresponds to the same event used in Figure~\ref{fig:EvReconstruction}. (a) An image of the hit reduction produced by \emph{TRestTrackReductionProcess}. The red circles represent the final position of reduced hits, which size corresponds with their energy value. The small grey circles on the background represent the hits of the \emph{parent track} used as input. (b) A polyline is added to this representation to visualize the hits inter-connectivity after the \emph{TRestTrackPathMinimizationProcess}. If path minimization works on the whole, it produces at times obviously unphysical connections, as our example illustrates. (c)~The unphysical connections are corrected using \emph{TRestTrackReconnectionProcess}.}
    \label{fig:TopologyProcess}
\end{figure}

\subsubsection{ Raw signal processes }

\begin{itemize}
\item \emph{TRestRawSignalShapingProcess:} This process realizes the simulation of the acquisition electronics signal shaper in a \emph{TRestRawSignalEvent}. It implements the convolution of an analytical response function with the input \emph{TRestRawSignalEvent}, presumably containing the original charge distribution produced in the detector. The analytical response function requires a single parameter, which is the \emph{shaping time}. However, this process offers the possibility to introduce any arbitrary wavefunction as response function, adding realism to the generated output.

\item \emph{TRestRawSignalAddNoiseProcess:} It is used to include the effect of electronic noise and emulate the fluctuations on the acquired time signal. A value is introduced as input metadata to define the amplitude of the noise. We use a basic noise method implemented in this process that assigns an independent random value, Gaussian distributed, to each of the bins inside a \emph{TRestRawSignalEvent}.
\end{itemize}

\subsection{The analysis tree}\label{sc:anTree}

The different \emph{event processes} can be combined in sequence to build a more complex processing chain. In REST, only the \emph{event data} produced in the last \emph{event process} will be saved to the output file\footnote{However, other \emph{metadata} information used in the processing chain, e.g. process parameters, simulation conditions, readout definition, or gas properties, will be stored without exception, including previous historical \emph{metadata} information}. There are two main reasons why it is not desirable to stock intermediate \emph{event data} into a single data file\footnote{Although no restrictions apply to produce intermediate files with a snapshot of the \emph{event data} at a particular step of the processing chain.}. First, we risk to pile-up, or replicate unnecessarily, data that might require to allocate a non negligible amount of disk space. Second, the traceability of changes introduced in the data might be lost by storing data at different \emph{levels} of processing inside a unique file. This possibility would add an undesirable degree of complexity to the future tracking of the data processing, if for example, we decide to continue processing data using a previously processed file with \emph{event data} at different processing levels but we start our \emph{event data} processing at an intermediate state.
% The appropriate procedure would be then to continue processing the intermediate file where intermediate \emph{event data} was stocked at the mentioned processing level, $p_l$.

%We have discussed the sequential philosophy of the \emph{event data} processing in REST.

However, the inconvenience of this scheme resides on the fact that, during the processing, the \emph{event data} is transformed in a way that information might be lost, as when we transform a \emph{TRestGeant4Event} into a \emph{TRestHitsEvent}. Therefore, it will be not available at the end of the \emph{event data} processing. The \emph{analysis tree} is a REST component that emerges to solve this problem. It is based on a ROOT TTree structure, and it is accessible at any stage of the \emph{event data} processing by any \emph{event process}. Any process in REST is allowed to create a new entry, or variable, inside the \emph{analysis tree} which will be always available in any REST file. Future processing may add new variables to the \emph{analysis tree} preserving the existing ones from previous processing levels. Therefore, the \emph{analysis tree} is used to gather relevant information along the processing chain that might not be anymore available at the \emph{event data} output of the last process.

% It is out of the scope of this document to describe in detail analysis processes. 

In this context, and just for classification purposes, we can distinguish two new types of \emph{event processes}, the \emph{analysis processes} and the \emph{pure analysis processes}. Both type of processes have in common that they do not modify or transform the input \emph{event data}, and are just dedicated to add new entries to the \emph{analysis tree}. Furthermore, the \emph{pure analysis processes} will not even require access to the \emph{event data}, being these processes the only ones that can be connected at any place of the processing chain without input/output \emph{event type} restrictions. For example, a \emph{pure analysis process} might be a process that reads a variable (or branch) in the \emph{analysis tree} to perform a multi-peak fit, and write the results of the fit in a \emph{metadata} structure.

